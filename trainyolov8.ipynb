{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7963790,"sourceType":"datasetVersion","datasetId":4685154},{"sourceId":7966369,"sourceType":"datasetVersion","datasetId":4687062},{"sourceId":7970423,"sourceType":"datasetVersion","datasetId":4689823}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install ultralytics\n!pip install torch\n!pip install onnxruntime","metadata":{"execution":{"iopub.status.busy":"2024-04-05T18:26:39.527892Z","iopub.execute_input":"2024-04-05T18:26:39.528695Z","iopub.status.idle":"2024-04-05T18:27:19.146343Z","shell.execute_reply.started":"2024-04-05T18:26:39.528656Z","shell.execute_reply":"2024-04-05T18:27:19.145402Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting ultralytics\n  Downloading ultralytics-8.1.43-py3-none-any.whl.metadata (40 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.4/40.4 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: matplotlib>=3.3.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (3.7.5)\nRequirement already satisfied: opencv-python>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (4.9.0.80)\nRequirement already satisfied: pillow>=7.1.2 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (9.5.0)\nRequirement already satisfied: pyyaml>=5.3.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (6.0.1)\nRequirement already satisfied: requests>=2.23.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.31.0)\nRequirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (1.11.4)\nRequirement already satisfied: torch>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.1.2)\nRequirement already satisfied: torchvision>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (0.16.2)\nRequirement already satisfied: tqdm>=4.64.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (4.66.1)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from ultralytics) (5.9.3)\nRequirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.10/site-packages (from ultralytics) (9.0.0)\nCollecting thop>=0.1.1 (from ultralytics)\n  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\nRequirement already satisfied: pandas>=1.1.4 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.1.4)\nRequirement already satisfied: seaborn>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (0.12.2)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\nRequirement already satisfied: numpy<2,>=1.20 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (21.3)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2023.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2024.2.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2024.3.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\nDownloading ultralytics-8.1.43-py3-none-any.whl (749 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m749.5/749.5 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\nInstalling collected packages: thop, ultralytics\nSuccessfully installed thop-0.1.1.post2209072238 ultralytics-8.1.43\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.1.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nCollecting onnxruntime\n  Downloading onnxruntime-1.17.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.3 kB)\nCollecting coloredlogs (from onnxruntime)\n  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: flatbuffers in /opt/conda/lib/python3.10/site-packages (from onnxruntime) (23.5.26)\nRequirement already satisfied: numpy>=1.21.6 in /opt/conda/lib/python3.10/site-packages (from onnxruntime) (1.26.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from onnxruntime) (21.3)\nRequirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from onnxruntime) (3.20.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from onnxruntime) (1.12)\nCollecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->onnxruntime) (3.1.1)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->onnxruntime) (1.3.0)\nDownloading onnxruntime-1.17.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: humanfriendly, coloredlogs, onnxruntime\nSuccessfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.17.1\n","output_type":"stream"}]},{"cell_type":"code","source":"!git clone https://github.com/llsrwsaint225/Bangkok-Bus-Dataset-YOLOV8","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-05T18:28:05.412994Z","iopub.execute_input":"2024-04-05T18:28:05.413727Z","iopub.status.idle":"2024-04-05T18:28:38.572608Z","shell.execute_reply.started":"2024-04-05T18:28:05.413689Z","shell.execute_reply":"2024-04-05T18:28:38.571754Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Cloning into 'Bangkok-Bus-Dataset-YOLOV8'...\nremote: Enumerating objects: 8187, done.\u001b[K\nremote: Counting objects: 100% (4/4), done.\u001b[K\nremote: Compressing objects: 100% (4/4), done.\u001b[K\nremote: Total 8187 (delta 0), reused 0 (delta 0), pack-reused 8183\u001b[K\nReceiving objects: 100% (8187/8187), 1.30 GiB | 50.28 MiB/s, done.\nResolving deltas: 100% (6/6), done.\nUpdating files: 100% (4090/4090), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"from ultralytics import YOLO\n\n# เป็นการสร้างโมเดลใหม่ขึ้นมา\n# model = YOLO('yolov8n.yaml')\n\n# โหลด pretrained model มาเพื่อให้เราไม่ต้องเทรนใหม่ทั้งหมดตั้งแต่เริ่ม\nmodel = YOLO('/kaggle/working/yolov8n.pt')\n\n# เทรนโมเดลโดยใช้ datasets ของเรา ซึ่งให้เราหาไฟล์ data.yaml \n# ในโฟลเดอร์ Datasets ของเราเเล้วเอา Path มาวางตรง data=\n# แนะนำว่าให้เอา Path ทั้งหมดมาเลย\n# epoch = 300 คือเราเทรนทั้งหมด 300 รอบ\npath = '/kaggle/working/Bangkok-Bus-Dataset-YOLOV8/data.yaml'\nresults = model.train(data=path, epochs=50)\n\n# ทดสอบโมเดลโดยใช้ validation datasets ที่เตรียมไว้\nresults = model.val()\n\n# เซฟโมเดลโดยให้โมเดลอยู่ใน ONNX format\nsuccess = model.export(format='onnx')","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-04-05T18:29:07.489687Z","iopub.execute_input":"2024-04-05T18:29:07.490046Z","iopub.status.idle":"2024-04-05T19:04:47.889406Z","shell.execute_reply.started":"2024-04-05T18:29:07.490018Z","shell.execute_reply":"2024-04-05T19:04:47.888519Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8n.pt to '/kaggle/working/yolov8n.pt'...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6.23M/6.23M [00:00<00:00, 111MB/s]\n","output_type":"stream"},{"name":"stdout","text":"Ultralytics YOLOv8.1.43 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=/kaggle/working/yolov8n.pt, data=/kaggle/working/Bangkok-Bus-Dataset-YOLOV8/data.yaml, epochs=50, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\nDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 755k/755k [00:00<00:00, 22.0MB/s]\n2024-04-05 18:29:15,482\tINFO util.py:124 -- Outdated packages:\n  ipywidgets==7.7.1 found, needs ipywidgets>=8\nRun `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n2024-04-05 18:29:17,178\tINFO util.py:124 -- Outdated packages:\n  ipywidgets==7.7.1 found, needs ipywidgets>=8\nRun `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n2024-04-05 18:29:19.449309: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-05 18:29:19.449407: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-05 18:29:19.582979: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Overriding model.yaml nc=80 with nc=5\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n 22        [15, 18, 21]  1    752287  ultralytics.nn.modules.head.Detect           [5, [64, 128, 256]]           \nModel summary: 225 layers, 3011823 parameters, 3011807 gradients, 8.2 GFLOPs\n\nTransferred 319/355 items from pretrained weights\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.6 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.4"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240405_182952-j7w7dpjh</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/llsrwsaint/YOLOv8/runs/j7w7dpjh' target=\"_blank\">train</a></strong> to <a href='https://wandb.ai/llsrwsaint/YOLOv8' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/llsrwsaint/YOLOv8' target=\"_blank\">https://wandb.ai/llsrwsaint/YOLOv8</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/llsrwsaint/YOLOv8/runs/j7w7dpjh' target=\"_blank\">https://wandb.ai/llsrwsaint/YOLOv8/runs/j7w7dpjh</a>"},"metadata":{}},{"name":"stdout","text":"Freezing layer 'model.22.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Bangkok-Bus-Dataset-YOLOV8/train/labels... 2043 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2043/2043 [00:02<00:00, 813.91it/s]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Bangkok-Bus-Dataset-YOLOV8/train/labels.cache\nWARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 9113, len(boxes) = 9293. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Bangkok-Bus-Dataset-YOLOV8/train/labels.cache... 2043 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2043/2043 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 9113, len(boxes) = 9293. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Plotting labels to runs/detect/train/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001111, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\nImage sizes 640 train, 640 val\nUsing 4 dataloader workers\nLogging results to \u001b[1mruns/detect/train\u001b[0m\nStarting training for 50 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       1/50      2.36G      1.364      2.314      1.673        112        640: 100%|██████████| 128/128 [00:32<00:00,  3.97it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:14<00:00,  4.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2043       9293      0.766      0.527      0.591      0.413\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       2/50       2.4G      1.163      1.474      1.485        105        640: 100%|██████████| 128/128 [00:26<00:00,  4.92it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:15<00:00,  4.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2043       9293      0.664      0.618      0.638      0.446\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       3/50      2.38G      1.091      1.298      1.428        127        640: 100%|██████████| 128/128 [00:26<00:00,  4.87it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:14<00:00,  4.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2043       9293      0.771       0.71      0.767      0.537\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       4/50      2.44G      1.068      1.198      1.395        103        640: 100%|██████████| 128/128 [00:26<00:00,  4.91it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:13<00:00,  4.72it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2043       9293      0.809      0.718      0.786      0.555\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       5/50      2.39G      1.006      1.094      1.346        117        640: 100%|██████████| 128/128 [00:25<00:00,  4.95it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:13<00:00,  4.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2043       9293      0.841      0.786      0.844      0.631\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       6/50       2.4G     0.9666      1.026      1.314        121        640: 100%|██████████| 128/128 [00:25<00:00,  5.03it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:13<00:00,  4.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2043       9293      0.833      0.801      0.856      0.654\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       7/50      2.39G     0.9149     0.9367      1.275         99        640: 100%|██████████| 128/128 [00:26<00:00,  4.91it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:13<00:00,  4.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2043       9293      0.813       0.81      0.855      0.671\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       8/50      2.34G     0.8982     0.9074      1.261         81        640: 100%|██████████| 128/128 [00:26<00:00,  4.89it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:13<00:00,  4.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2043       9293      0.858      0.812       0.88      0.683\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       9/50      2.38G     0.8631     0.8659      1.231        101        640: 100%|██████████| 128/128 [00:26<00:00,  4.90it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:13<00:00,  4.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2043       9293      0.893      0.832      0.894      0.718\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      10/50      2.34G     0.8448     0.8294      1.223        110        640: 100%|██████████| 128/128 [00:25<00:00,  4.93it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:12<00:00,  4.97it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2043       9293       0.91      0.856      0.915      0.738\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      11/50      2.33G     0.8241     0.8114      1.209        108        640: 100%|██████████| 128/128 [00:25<00:00,  4.99it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:12<00:00,  5.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2043       9293      0.904      0.855      0.915      0.735\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      12/50      2.34G     0.8159      0.795      1.204        114        640: 100%|██████████| 128/128 [00:25<00:00,  5.03it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:12<00:00,  5.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2043       9293      0.912      0.883       0.93      0.767\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      13/50      2.33G     0.7944     0.7577      1.182        124        640: 100%|██████████| 128/128 [00:25<00:00,  5.00it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:12<00:00,  4.96it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2043       9293      0.919      0.888      0.934      0.774\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      14/50      2.39G     0.7806     0.7435       1.18        112        640: 100%|██████████| 128/128 [00:25<00:00,  5.10it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:12<00:00,  4.95it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2043       9293      0.911      0.886      0.935      0.781\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      15/50      2.38G     0.7674     0.7231      1.165        138        640: 100%|██████████| 128/128 [00:26<00:00,  4.91it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:12<00:00,  5.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2043       9293      0.917      0.883      0.939      0.766\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      16/50      2.38G     0.7572     0.7098      1.161         83        640: 100%|██████████| 128/128 [00:25<00:00,  5.01it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:12<00:00,  4.98it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2043       9293      0.922      0.909      0.948      0.793\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      17/50      2.39G     0.7467     0.7152      1.158         95        640: 100%|██████████| 128/128 [00:26<00:00,  4.92it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:12<00:00,  4.94it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       2043       9293      0.923      0.901      0.945      0.793\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      18/50      2.39G     0.7295     0.6821      1.141        116        640: 100%|██████████| 128/128 [00:25<00:00,  4.99it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:13<00:00,  4.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2043       9293      0.926      0.907      0.953      0.791\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      19/50      2.33G     0.7179     0.6556      1.134        145        640: 100%|██████████| 128/128 [00:26<00:00,  4.91it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:12<00:00,  4.99it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2043       9293      0.937       0.91      0.958      0.813\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      20/50      2.33G     0.7107     0.6572      1.134        109        640: 100%|██████████| 128/128 [00:25<00:00,  4.99it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:12<00:00,  5.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2043       9293      0.936      0.912      0.959      0.823\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      21/50      2.33G     0.7055     0.6482      1.129         99        640: 100%|██████████| 128/128 [00:25<00:00,  5.01it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:12<00:00,  5.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2043       9293      0.938      0.926      0.962      0.821\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      22/50      2.39G      0.701     0.6396      1.126        116        640: 100%|██████████| 128/128 [00:25<00:00,  4.96it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:13<00:00,  4.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2043       9293      0.946      0.928      0.967      0.836\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      23/50      2.33G     0.6881     0.6244      1.116         97        640: 100%|██████████| 128/128 [00:25<00:00,  4.99it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:12<00:00,  5.00it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2043       9293      0.944      0.932      0.969      0.842\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      24/50      2.39G     0.6782     0.6149      1.108        114        640: 100%|██████████| 128/128 [00:26<00:00,  4.91it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:12<00:00,  5.00it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2043       9293      0.949      0.935      0.971      0.849\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      25/50      2.33G     0.6632     0.5988      1.099        139        640: 100%|██████████| 128/128 [00:26<00:00,  4.92it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:12<00:00,  4.95it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2043       9293      0.938      0.932      0.967      0.846\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      26/50      2.38G     0.6633     0.5904      1.098        133        640: 100%|██████████| 128/128 [00:25<00:00,  4.94it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:13<00:00,  4.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2043       9293      0.955      0.936      0.974      0.851\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      27/50      2.38G     0.6442     0.5838      1.087        111        640: 100%|██████████| 128/128 [00:25<00:00,  4.95it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:13<00:00,  4.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2043       9293      0.954      0.942      0.974      0.849\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      28/50      2.33G     0.6482     0.5759       1.09        158        640: 100%|██████████| 128/128 [00:25<00:00,  4.95it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:12<00:00,  4.96it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2043       9293      0.956      0.945      0.977      0.859\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      29/50      2.33G     0.6434     0.5714      1.089         97        640: 100%|██████████| 128/128 [00:26<00:00,  4.91it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:12<00:00,  5.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2043       9293      0.957      0.942      0.978      0.863\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      30/50      2.33G     0.6348      0.555      1.076        114        640: 100%|██████████| 128/128 [00:25<00:00,  5.00it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:13<00:00,  4.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2043       9293      0.956      0.936      0.976      0.863\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      31/50      2.33G     0.6293     0.5558       1.08        105        640: 100%|██████████| 128/128 [00:25<00:00,  5.03it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:13<00:00,  4.85it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       2043       9293      0.955      0.952       0.98      0.871\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      32/50      2.33G     0.6202     0.5509      1.072         89        640: 100%|██████████| 128/128 [00:25<00:00,  4.93it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:13<00:00,  4.83it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       2043       9293      0.959      0.949      0.981      0.871\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      33/50      2.33G     0.6187     0.5464      1.073        144        640: 100%|██████████| 128/128 [00:25<00:00,  4.94it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:12<00:00,  4.97it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2043       9293      0.964      0.948      0.982      0.875\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      34/50      2.33G     0.6091     0.5348      1.067        140        640: 100%|██████████| 128/128 [00:25<00:00,  4.92it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:13<00:00,  4.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2043       9293      0.961      0.949      0.981      0.872\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      35/50      2.33G     0.6023     0.5261      1.062        135        640: 100%|██████████| 128/128 [00:25<00:00,  5.01it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:13<00:00,  4.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2043       9293      0.967      0.954      0.983      0.879\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      36/50      2.38G     0.5954     0.5158      1.059        132        640: 100%|██████████| 128/128 [00:25<00:00,  4.94it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:12<00:00,  4.99it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2043       9293      0.962      0.956      0.984      0.884\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      37/50      2.33G     0.5896     0.5199      1.057         86        640: 100%|██████████| 128/128 [00:25<00:00,  4.94it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:12<00:00,  5.02it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2043       9293      0.967      0.952      0.984      0.885\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      38/50      2.38G     0.5828     0.5141      1.051         87        640: 100%|██████████| 128/128 [00:25<00:00,  4.96it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:13<00:00,  4.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2043       9293       0.97      0.957      0.986      0.893\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      39/50      2.33G     0.5734     0.5022      1.049         97        640: 100%|██████████| 128/128 [00:25<00:00,  5.03it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:13<00:00,  4.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2043       9293      0.972      0.955      0.985      0.893\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      40/50      2.33G     0.5802     0.5025      1.053         92        640: 100%|██████████| 128/128 [00:25<00:00,  4.98it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:12<00:00,  5.02it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2043       9293       0.97      0.957      0.986      0.893\nClosing dataloader mosaic\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      41/50      2.33G     0.5213     0.4218       1.02         46        640: 100%|██████████| 128/128 [00:26<00:00,  4.78it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:12<00:00,  5.02it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2043       9293      0.969      0.955      0.986      0.894\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      42/50      2.33G     0.5048     0.3975      1.006         58        640: 100%|██████████| 128/128 [00:24<00:00,  5.25it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:13<00:00,  4.90it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       2043       9293      0.971      0.963      0.987      0.897\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      43/50      2.37G     0.4866     0.3774     0.9904         58        640: 100%|██████████| 128/128 [00:24<00:00,  5.33it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:13<00:00,  4.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2043       9293      0.974      0.967      0.989      0.903\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      44/50      2.33G     0.4766     0.3676     0.9825         44        640: 100%|██████████| 128/128 [00:23<00:00,  5.37it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:13<00:00,  4.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2043       9293      0.976      0.966      0.989      0.908\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      45/50      2.33G      0.466     0.3616     0.9789         42        640: 100%|██████████| 128/128 [00:24<00:00,  5.17it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:12<00:00,  5.00it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2043       9293      0.979      0.968       0.99      0.914\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      46/50      2.33G     0.4518     0.3517     0.9694         53        640: 100%|██████████| 128/128 [00:24<00:00,  5.26it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:12<00:00,  5.00it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       2043       9293      0.982      0.969       0.99      0.916\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      47/50      2.33G     0.4522     0.3498      0.966         50        640: 100%|██████████| 128/128 [00:24<00:00,  5.25it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:12<00:00,  4.98it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2043       9293       0.98      0.969      0.991      0.916\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      48/50      2.33G     0.4431      0.341     0.9651         52        640: 100%|██████████| 128/128 [00:24<00:00,  5.32it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:13<00:00,  4.85it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       2043       9293      0.982      0.969      0.991      0.918\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      49/50      2.33G     0.4425     0.3399     0.9575         52        640: 100%|██████████| 128/128 [00:23<00:00,  5.36it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:13<00:00,  4.91it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2043       9293       0.98      0.973      0.991      0.923\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      50/50      2.33G     0.4325     0.3354     0.9543         44        640: 100%|██████████| 128/128 [00:24<00:00,  5.27it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:12<00:00,  4.98it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2043       9293      0.981      0.972      0.992      0.924\n\n50 epochs completed in 0.552 hours.\nOptimizer stripped from runs/detect/train/weights/last.pt, 6.2MB\nOptimizer stripped from runs/detect/train/weights/best.pt, 6.2MB\n\nValidating runs/detect/train/weights/best.pt...\nUltralytics YOLOv8.1.43 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\nModel summary (fused): 168 layers, 3006623 parameters, 0 gradients, 8.1 GFLOPs\n","output_type":"stream"},{"name":"stderr","text":"                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:18<00:00,  3.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2043       9293      0.981      0.972      0.992      0.924\n              BMTA-bus       2043       1959      0.989      0.984      0.995      0.958\n       Bus Line Number       2043       2336      0.966      0.967       0.99      0.882\n       Bus Side Number       2043       2214      0.982      0.965      0.991      0.937\n      Destination Sign       2043       2226      0.973      0.954      0.987      0.895\n               TSB-Bus       2043        558      0.995      0.989      0.995      0.948\nSpeed: 0.1ms preprocess, 1.5ms inference, 0.0ms loss, 1.3ms postprocess per image\nResults saved to \u001b[1mruns/detect/train\u001b[0m\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='15.518 MB of 15.518 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>▃▆███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁</td></tr><tr><td>lr/pg1</td><td>▃▆███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁</td></tr><tr><td>lr/pg2</td><td>▃▆███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁</td></tr><tr><td>metrics/mAP50(B)</td><td>▁▂▄▄▆▆▆▆▇▇▇▇▇▇▇▇▇███████████████████████</td></tr><tr><td>metrics/mAP50-95(B)</td><td>▁▁▃▃▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████████</td></tr><tr><td>metrics/precision(B)</td><td>▃▁▃▄▅▄▅▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████████████</td></tr><tr><td>metrics/recall(B)</td><td>▁▂▄▄▅▅▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇███████████████████</td></tr><tr><td>model/GFLOPs</td><td>▁</td></tr><tr><td>model/parameters</td><td>▁</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>▁</td></tr><tr><td>train/box_loss</td><td>█▆▆▆▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>train/cls_loss</td><td>█▅▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>train/dfl_loss</td><td>█▆▆▅▅▄▄▄▃▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>val/box_loss</td><td>██▇▆▅▅▅▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>val/cls_loss</td><td>██▆▅▄▄▄▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/dfl_loss</td><td>██▇▆▅▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>3e-05</td></tr><tr><td>lr/pg1</td><td>3e-05</td></tr><tr><td>lr/pg2</td><td>3e-05</td></tr><tr><td>metrics/mAP50(B)</td><td>0.99156</td></tr><tr><td>metrics/mAP50-95(B)</td><td>0.92407</td></tr><tr><td>metrics/precision(B)</td><td>0.98116</td></tr><tr><td>metrics/recall(B)</td><td>0.97186</td></tr><tr><td>model/GFLOPs</td><td>8.198</td></tr><tr><td>model/parameters</td><td>3011823</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>1.536</td></tr><tr><td>train/box_loss</td><td>0.43245</td></tr><tr><td>train/cls_loss</td><td>0.3354</td></tr><tr><td>train/dfl_loss</td><td>0.95428</td></tr><tr><td>val/box_loss</td><td>0.38724</td></tr><tr><td>val/cls_loss</td><td>0.30193</td></tr><tr><td>val/dfl_loss</td><td>0.9048</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">train</strong> at: <a href='https://wandb.ai/llsrwsaint/YOLOv8/runs/j7w7dpjh' target=\"_blank\">https://wandb.ai/llsrwsaint/YOLOv8/runs/j7w7dpjh</a><br/>Synced 6 W&B file(s), 24 media file(s), 5 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240405_182952-j7w7dpjh/logs</code>"},"metadata":{}},{"name":"stdout","text":"Ultralytics YOLOv8.1.43 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\nModel summary (fused): 168 layers, 3006623 parameters, 0 gradients, 8.1 GFLOPs\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Bangkok-Bus-Dataset-YOLOV8/train/labels.cache... 2043 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2043/2043 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 9113, len(boxes) = 9293. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n","output_type":"stream"},{"name":"stderr","text":"\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 128/128 [00:19<00:00,  6.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2043       9293      0.981      0.972      0.992      0.924\n              BMTA-bus       2043       1959       0.99      0.984      0.995      0.958\n       Bus Line Number       2043       2336      0.967      0.967       0.99      0.882\n       Bus Side Number       2043       2214      0.982      0.965      0.991      0.938\n      Destination Sign       2043       2226      0.973      0.954      0.987      0.895\n               TSB-Bus       2043        558      0.995      0.989      0.995      0.946\nSpeed: 0.2ms preprocess, 1.7ms inference, 0.0ms loss, 1.0ms postprocess per image\nResults saved to \u001b[1mruns/detect/train2\u001b[0m\nUltralytics YOLOv8.1.43 🚀 Python-3.10.13 torch-2.1.2 CPU (Intel Xeon 2.00GHz)\n\n\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'runs/detect/train/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 9, 8400) (6.0 MB)\n\n\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.15.0 opset 17...\n\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 0.7s, saved as 'runs/detect/train/weights/best.onnx' (11.7 MB)\n\nExport complete (2.2s)\nResults saved to \u001b[1m/kaggle/working/runs/detect/train/weights\u001b[0m\nPredict:         yolo predict task=detect model=runs/detect/train/weights/best.onnx imgsz=640  \nValidate:        yolo val task=detect model=runs/detect/train/weights/best.onnx imgsz=640 data=/kaggle/working/Bangkok-Bus-Dataset-YOLOV8/data.yaml  \nVisualize:       https://netron.app\n","output_type":"stream"}]},{"cell_type":"code","source":"from ultralytics import YOLO\n\n# ในวงเล็บใส่ path ของโมเดล\nmodel = YOLO('/kaggle/working/runs/detect/train/weights/best.pt')\n\n# parameter ทั้งหมดจะเรียงดังนี้ \n#  (path ของรูปที่เราต้องการจะpredict,\n#   เซฟรูปที่ต้องการ predict,\n#   ค่าความมั่นใจที่จะทำนาย ถ้าเกิดทำนายออกมาเเล้วค่าความมั่นใจมากกว่าค่านี้ ถึงจะทำนายออกมา) \n           \nmodel.predict('/kaggle/input/test-model', \n              save=True,\n              conf=0.2)","metadata":{"execution":{"iopub.status.busy":"2024-04-05T19:08:58.089065Z","iopub.execute_input":"2024-04-05T19:08:58.089816Z","iopub.status.idle":"2024-04-05T19:09:04.375947Z","shell.execute_reply.started":"2024-04-05T19:08:58.089772Z","shell.execute_reply":"2024-04-05T19:09:04.374926Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"\nimage 1/18 /kaggle/input/test-model/20231116_080107024_iOS.jpg: 640x512 1 BMTA-bus, 1 Bus Line Number, 1 Destination Sign, 66.0ms\nimage 2/18 /kaggle/input/test-model/407116192_2082839512060607_5810245313399214706_n.jpg: 640x480 1 BMTA-bus, 1 Bus Line Number, 1 Bus Side Number, 1 Destination Sign, 12.4ms\nimage 3/18 /kaggle/input/test-model/407687504_2083303268680898_5328550823278390157_n.jpg: 640x480 1 Bus Line Number, 1 Bus Side Number, 1 Destination Sign, 1 TSB-Bus, 6.9ms\nimage 4/18 /kaggle/input/test-model/414557972_2094715790872979_6185664876338128497_n.jpg: 640x480 1 BMTA-bus, 1 Bus Line Number, 1 Bus Side Number, 1 Destination Sign, 6.9ms\nimage 5/18 /kaggle/input/test-model/419664394_2106648946346330_1781686041994578657_n.jpg: 480x640 2 BMTA-buss, 3 Bus Line Numbers, 1 Bus Side Number, 1 Destination Sign, 56.2ms\nimage 6/18 /kaggle/input/test-model/425396681_2119497351728156_6393711250584787541_n.jpg: 640x480 1 BMTA-bus, 1 Bus Line Number, 1 Bus Side Number, 2 Destination Signs, 7.6ms\nimage 7/18 /kaggle/input/test-model/429652861_2137514106593147_6380796732375205439_n.jpg: 480x640 1 BMTA-bus, 1 Bus Line Number, 1 Bus Side Number, 1 Destination Sign, 7.8ms\nimage 8/18 /kaggle/input/test-model/429761849_2136305293380695_1185578989535131822_n.jpg: 480x640 1 BMTA-bus, 2 Bus Line Numbers, 2 Bus Side Numbers, 2 Destination Signs, 1 TSB-Bus, 6.8ms\nimage 9/18 /kaggle/input/test-model/FullSizeRender.jpg: 640x480 1 BMTA-bus, 2 Destination Signs, 7.5ms\nimage 10/18 /kaggle/input/test-model/IMG_0050.JPG: 480x640 1 BMTA-bus, 3 Bus Line Numbers, 2 Bus Side Numbers, 1 Destination Sign, 7.6ms\nimage 11/18 /kaggle/input/test-model/IMG_0051.JPG: 480x640 1 BMTA-bus, 1 Bus Line Number, 3 Bus Side Numbers, 1 Destination Sign, 7.0ms\nimage 12/18 /kaggle/input/test-model/IMG_0391.JPG: 480x640 1 BMTA-bus, 1 Bus Line Number, 1 Bus Side Number, 1 Destination Sign, 7.6ms\nimage 13/18 /kaggle/input/test-model/IMG_0421.JPG: 640x480 1 BMTA-bus, 1 Bus Line Number, 1 Bus Side Number, 1 Destination Sign, 7.6ms\nimage 14/18 /kaggle/input/test-model/IMG_0422.JPG: 640x480 1 BMTA-bus, 2 Bus Line Numbers, 1 Bus Side Number, 1 Destination Sign, 6.9ms\nimage 15/18 /kaggle/input/test-model/IMG_0564.JPG: 640x480 3 Bus Line Numbers, 3 Bus Side Numbers, 2 Destination Signs, 2 TSB-Buss, 7.1ms\nimage 16/18 /kaggle/input/test-model/IMG_0575.JPG: 480x640 3 BMTA-buss, 3 Bus Line Numbers, 2 Bus Side Numbers, 2 Destination Signs, 8.1ms\nimage 17/18 /kaggle/input/test-model/IMG_0664.JPG: 640x480 1 BMTA-bus, 5 Bus Line Numbers, 1 Bus Side Number, 2 Destination Signs, 7.9ms\nimage 18/18 /kaggle/input/test-model/IMG_1976.jpeg: 640x480 1 Bus Line Number, 1 Bus Side Number, 2 Destination Signs, 1 TSB-Bus, 6.9ms\nSpeed: 2.9ms preprocess, 13.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"[ultralytics.engine.results.Results object with attributes:\n \n boxes: ultralytics.engine.results.Boxes object\n keypoints: None\n masks: None\n names: {0: 'BMTA-bus', 1: 'Bus Line Number', 2: 'Bus Side Number', 3: 'Destination Sign', 4: 'TSB-Bus'}\n obb: None\n orig_img: array([[[239, 245, 244],\n         [236, 242, 241],\n         [220, 225, 224],\n         ...,\n         [ 43,  57,  39],\n         [ 38,  52,  34],\n         [ 46,  60,  42]],\n \n        [[229, 235, 234],\n         [222, 228, 227],\n         [228, 233, 232],\n         ...,\n         [ 65,  79,  61],\n         [ 72,  86,  68],\n         [ 95, 109,  91]],\n \n        [[221, 226, 225],\n         [229, 234, 233],\n         [241, 246, 245],\n         ...,\n         [ 86, 101,  80],\n         [ 96, 111,  90],\n         [104, 119,  98]],\n \n        ...,\n \n        [[150, 143, 140],\n         [154, 147, 144],\n         [156, 149, 146],\n         ...,\n         [ 99, 111, 117],\n         [ 77,  89,  95],\n         [ 85,  97, 103]],\n \n        [[149, 142, 139],\n         [153, 146, 143],\n         [152, 145, 142],\n         ...,\n         [ 97, 109, 115],\n         [ 71,  81,  88],\n         [ 81,  91,  98]],\n \n        [[147, 140, 137],\n         [143, 136, 133],\n         [142, 135, 132],\n         ...,\n         [102, 114, 120],\n         [ 76,  86,  93],\n         [ 60,  70,  77]]], dtype=uint8)\n orig_shape: (1384, 1078)\n path: '/kaggle/input/test-model/20231116_080107024_iOS.jpg'\n probs: None\n save_dir: 'runs/detect/predict'\n speed: {'preprocess': 3.6742687225341797, 'inference': 66.00403785705566, 'postprocess': 1.6489028930664062},\n ultralytics.engine.results.Results object with attributes:\n \n boxes: ultralytics.engine.results.Boxes object\n keypoints: None\n masks: None\n names: {0: 'BMTA-bus', 1: 'Bus Line Number', 2: 'Bus Side Number', 3: 'Destination Sign', 4: 'TSB-Bus'}\n obb: None\n orig_img: array([[[ 11,  17,  36],\n         [  9,  15,  34],\n         [  7,  13,  32],\n         ...,\n         [110, 128, 175],\n         [110, 128, 175],\n         [110, 128, 175]],\n \n        [[ 11,  17,  36],\n         [ 10,  16,  35],\n         [  8,  14,  33],\n         ...,\n         [110, 128, 175],\n         [110, 128, 175],\n         [110, 128, 175]],\n \n        [[ 11,  17,  36],\n         [  9,  15,  34],\n         [  7,  13,  32],\n         ...,\n         [110, 128, 175],\n         [110, 128, 175],\n         [110, 128, 175]],\n \n        ...,\n \n        [[121, 152, 185],\n         [103, 134, 167],\n         [103, 134, 167],\n         ...,\n         [ 62,  75, 101],\n         [ 62,  75, 101],\n         [ 61,  73, 101]],\n \n        [[135, 166, 199],\n         [125, 156, 189],\n         [125, 156, 189],\n         ...,\n         [ 57,  70,  96],\n         [ 57,  70,  96],\n         [ 57,  69,  97]],\n \n        [[122, 153, 186],\n         [120, 151, 184],\n         [128, 159, 192],\n         ...,\n         [ 63,  76, 102],\n         [ 63,  76, 102],\n         [ 63,  75, 103]]], dtype=uint8)\n orig_shape: (1146, 843)\n path: '/kaggle/input/test-model/407116192_2082839512060607_5810245313399214706_n.jpg'\n probs: None\n save_dir: 'runs/detect/predict'\n speed: {'preprocess': 2.401113510131836, 'inference': 12.354612350463867, 'postprocess': 1.4259815216064453},\n ultralytics.engine.results.Results object with attributes:\n \n boxes: ultralytics.engine.results.Boxes object\n keypoints: None\n masks: None\n names: {0: 'BMTA-bus', 1: 'Bus Line Number', 2: 'Bus Side Number', 3: 'Destination Sign', 4: 'TSB-Bus'}\n obb: None\n orig_img: array([[[ 54,  39,  36],\n         [ 54,  39,  36],\n         [ 54,  39,  36],\n         ...,\n         [247, 191,  96],\n         [247, 191,  96],\n         [247, 191,  96]],\n \n        [[ 52,  37,  34],\n         [ 52,  37,  34],\n         [ 52,  37,  34],\n         ...,\n         [247, 191,  96],\n         [247, 191,  96],\n         [247, 191,  96]],\n \n        [[ 50,  35,  32],\n         [ 50,  35,  32],\n         [ 50,  35,  32],\n         ...,\n         [248, 192,  97],\n         [248, 192,  97],\n         [248, 192,  97]],\n \n        ...,\n \n        [[173, 154, 151],\n         [173, 154, 151],\n         [173, 154, 151],\n         ...,\n         [206, 172, 148],\n         [202, 168, 144],\n         [199, 165, 141]],\n \n        [[169, 150, 147],\n         [169, 150, 147],\n         [169, 150, 147],\n         ...,\n         [211, 177, 153],\n         [206, 172, 148],\n         [199, 165, 141]],\n \n        [[168, 149, 146],\n         [168, 149, 146],\n         [168, 149, 146],\n         ...,\n         [209, 175, 151],\n         [202, 168, 144],\n         [194, 160, 136]]], dtype=uint8)\n orig_shape: (2048, 1536)\n path: '/kaggle/input/test-model/407687504_2083303268680898_5328550823278390157_n.jpg'\n probs: None\n save_dir: 'runs/detect/predict'\n speed: {'preprocess': 3.677845001220703, 'inference': 6.895303726196289, 'postprocess': 1.3735294342041016},\n ultralytics.engine.results.Results object with attributes:\n \n boxes: ultralytics.engine.results.Boxes object\n keypoints: None\n masks: None\n names: {0: 'BMTA-bus', 1: 'Bus Line Number', 2: 'Bus Side Number', 3: 'Destination Sign', 4: 'TSB-Bus'}\n obb: None\n orig_img: array([[[242, 244, 225],\n         [242, 244, 225],\n         [242, 244, 225],\n         ...,\n         [  4,  36,  17],\n         [  4,  36,  17],\n         [  4,  36,  17]],\n \n        [[241, 243, 224],\n         [241, 243, 224],\n         [241, 243, 224],\n         ...,\n         [  4,  36,  17],\n         [  4,  36,  17],\n         [  4,  36,  17]],\n \n        [[241, 243, 224],\n         [241, 243, 224],\n         [241, 243, 224],\n         ...,\n         [  4,  36,  17],\n         [  4,  36,  17],\n         [  4,  36,  17]],\n \n        ...,\n \n        [[164, 163, 159],\n         [180, 179, 175],\n         [187, 186, 182],\n         ...,\n         [161, 167, 166],\n         [164, 170, 169],\n         [162, 168, 167]],\n \n        [[156, 155, 151],\n         [171, 170, 166],\n         [182, 181, 177],\n         ...,\n         [161, 167, 166],\n         [165, 171, 170],\n         [161, 167, 166]],\n \n        [[154, 153, 149],\n         [161, 160, 156],\n         [164, 163, 159],\n         ...,\n         [161, 167, 166],\n         [163, 169, 168],\n         [156, 162, 161]]], dtype=uint8)\n orig_shape: (2048, 1536)\n path: '/kaggle/input/test-model/414557972_2094715790872979_6185664876338128497_n.jpg'\n probs: None\n save_dir: 'runs/detect/predict'\n speed: {'preprocess': 2.644062042236328, 'inference': 6.873846054077148, 'postprocess': 1.4240741729736328},\n ultralytics.engine.results.Results object with attributes:\n \n boxes: ultralytics.engine.results.Boxes object\n keypoints: None\n masks: None\n names: {0: 'BMTA-bus', 1: 'Bus Line Number', 2: 'Bus Side Number', 3: 'Destination Sign', 4: 'TSB-Bus'}\n obb: None\n orig_img: array([[[222, 237, 240],\n         [241, 255, 255],\n         [205, 214, 228],\n         ...,\n         [120, 159, 133],\n         [136, 177, 150],\n         [132, 175, 148]],\n \n        [[241, 255, 255],\n         [229, 241, 251],\n         [165, 174, 188],\n         ...,\n         [133, 172, 146],\n         [139, 180, 153],\n         [125, 168, 141]],\n \n        [[241, 253, 255],\n         [190, 201, 215],\n         [125, 132, 151],\n         ...,\n         [103, 142, 116],\n         [ 99, 140, 113],\n         [ 88, 129, 102]],\n \n        ...,\n \n        [[207, 208, 206],\n         [201, 202, 200],\n         [196, 197, 195],\n         ...,\n         [174, 175, 179],\n         [176, 177, 181],\n         [174, 175, 179]],\n \n        [[194, 195, 193],\n         [194, 195, 193],\n         [196, 197, 195],\n         ...,\n         [164, 163, 167],\n         [162, 161, 165],\n         [163, 162, 166]],\n \n        [[184, 185, 183],\n         [189, 190, 188],\n         [199, 200, 198],\n         ...,\n         [168, 167, 171],\n         [160, 159, 163],\n         [161, 160, 164]]], dtype=uint8)\n orig_shape: (1536, 2048)\n path: '/kaggle/input/test-model/419664394_2106648946346330_1781686041994578657_n.jpg'\n probs: None\n save_dir: 'runs/detect/predict'\n speed: {'preprocess': 2.5186538696289062, 'inference': 56.23960494995117, 'postprocess': 1.3668537139892578},\n ultralytics.engine.results.Results object with attributes:\n \n boxes: ultralytics.engine.results.Boxes object\n keypoints: None\n masks: None\n names: {0: 'BMTA-bus', 1: 'Bus Line Number', 2: 'Bus Side Number', 3: 'Destination Sign', 4: 'TSB-Bus'}\n obb: None\n orig_img: array([[[218, 241, 249],\n         [218, 241, 249],\n         [218, 241, 249],\n         ...,\n         [235, 228, 213],\n         [235, 228, 213],\n         [235, 228, 213]],\n \n        [[218, 241, 249],\n         [218, 241, 249],\n         [218, 241, 249],\n         ...,\n         [235, 228, 213],\n         [235, 228, 213],\n         [235, 228, 213]],\n \n        [[218, 241, 249],\n         [218, 241, 249],\n         [218, 241, 249],\n         ...,\n         [235, 228, 213],\n         [235, 228, 213],\n         [235, 228, 213]],\n \n        ...,\n \n        [[190, 202, 206],\n         [191, 203, 207],\n         [189, 201, 205],\n         ...,\n         [197, 210, 212],\n         [193, 205, 207],\n         [189, 202, 204]],\n \n        [[193, 205, 209],\n         [191, 203, 207],\n         [186, 198, 202],\n         ...,\n         [198, 210, 212],\n         [198, 207, 210],\n         [196, 208, 210]],\n \n        [[197, 209, 213],\n         [191, 203, 207],\n         [183, 195, 199],\n         ...,\n         [196, 205, 208],\n         [198, 207, 210],\n         [200, 209, 212]]], dtype=uint8)\n orig_shape: (2048, 1536)\n path: '/kaggle/input/test-model/425396681_2119497351728156_6393711250584787541_n.jpg'\n probs: None\n save_dir: 'runs/detect/predict'\n speed: {'preprocess': 2.6323795318603516, 'inference': 7.614612579345703, 'postprocess': 1.4433860778808594},\n ultralytics.engine.results.Results object with attributes:\n \n boxes: ultralytics.engine.results.Boxes object\n keypoints: None\n masks: None\n names: {0: 'BMTA-bus', 1: 'Bus Line Number', 2: 'Bus Side Number', 3: 'Destination Sign', 4: 'TSB-Bus'}\n obb: None\n orig_img: array([[[ 12,   7,   6],\n         [ 15,  10,   9],\n         [ 20,  15,  14],\n         ...,\n         [ 70,  80,  80],\n         [ 55,  65,  65],\n         [ 41,  51,  51]],\n \n        [[ 14,   9,   8],\n         [ 17,  12,  11],\n         [ 20,  15,  14],\n         ...,\n         [ 78,  88,  88],\n         [ 55,  65,  65],\n         [ 43,  53,  53]],\n \n        [[ 17,  12,  11],\n         [ 19,  14,  13],\n         [ 21,  16,  15],\n         ...,\n         [ 88,  96,  96],\n         [ 52,  60,  60],\n         [ 42,  50,  50]],\n \n        ...,\n \n        [[140, 141, 139],\n         [134, 135, 133],\n         [126, 127, 125],\n         ...,\n         [195, 192, 194],\n         [196, 193, 195],\n         [197, 194, 196]],\n \n        [[138, 139, 137],\n         [132, 133, 131],\n         [124, 125, 123],\n         ...,\n         [194, 191, 193],\n         [195, 192, 194],\n         [196, 193, 195]],\n \n        [[136, 137, 135],\n         [131, 132, 130],\n         [123, 124, 122],\n         ...,\n         [193, 190, 192],\n         [194, 191, 193],\n         [195, 192, 194]]], dtype=uint8)\n orig_shape: (1536, 2048)\n path: '/kaggle/input/test-model/429652861_2137514106593147_6380796732375205439_n.jpg'\n probs: None\n save_dir: 'runs/detect/predict'\n speed: {'preprocess': 2.754688262939453, 'inference': 7.7667236328125, 'postprocess': 1.363515853881836},\n ultralytics.engine.results.Results object with attributes:\n \n boxes: ultralytics.engine.results.Boxes object\n keypoints: None\n masks: None\n names: {0: 'BMTA-bus', 1: 'Bus Line Number', 2: 'Bus Side Number', 3: 'Destination Sign', 4: 'TSB-Bus'}\n obb: None\n orig_img: array([[[ 36,  23,   7],\n         [ 36,  23,   7],\n         [ 36,  23,   7],\n         ...,\n         [ 99, 103, 255],\n         [ 19,  20, 160],\n         [ 46,  45, 178]],\n \n        [[ 36,  23,   7],\n         [ 36,  23,   7],\n         [ 36,  23,   7],\n         ...,\n         [100, 104, 255],\n         [ 21,  22, 162],\n         [ 45,  44, 177]],\n \n        [[ 36,  23,   7],\n         [ 36,  23,   7],\n         [ 36,  23,   7],\n         ...,\n         [103, 105, 255],\n         [ 26,  25, 165],\n         [ 46,  42, 177]],\n \n        ...,\n \n        [[ 89,  86,  81],\n         [ 90,  87,  82],\n         [ 90,  87,  82],\n         ...,\n         [ 39,  44,  47],\n         [ 39,  44,  47],\n         [ 39,  44,  47]],\n \n        [[ 89,  86,  81],\n         [ 90,  87,  82],\n         [ 91,  88,  83],\n         ...,\n         [ 41,  46,  49],\n         [ 41,  46,  49],\n         [ 41,  46,  49]],\n \n        [[ 90,  87,  82],\n         [ 91,  88,  83],\n         [ 92,  89,  84],\n         ...,\n         [ 42,  47,  50],\n         [ 42,  47,  50],\n         [ 42,  47,  50]]], dtype=uint8)\n orig_shape: (1536, 2048)\n path: '/kaggle/input/test-model/429761849_2136305293380695_1185578989535131822_n.jpg'\n probs: None\n save_dir: 'runs/detect/predict'\n speed: {'preprocess': 2.548694610595703, 'inference': 6.764411926269531, 'postprocess': 1.3811588287353516},\n ultralytics.engine.results.Results object with attributes:\n \n boxes: ultralytics.engine.results.Boxes object\n keypoints: None\n masks: None\n names: {0: 'BMTA-bus', 1: 'Bus Line Number', 2: 'Bus Side Number', 3: 'Destination Sign', 4: 'TSB-Bus'}\n obb: None\n orig_img: array([[[252, 218, 182],\n         [252, 218, 182],\n         [252, 218, 182],\n         ...,\n         [253, 255, 224],\n         [250, 254, 225],\n         [248, 253, 224]],\n \n        [[252, 218, 182],\n         [252, 218, 182],\n         [252, 218, 182],\n         ...,\n         [252, 255, 223],\n         [250, 254, 225],\n         [248, 253, 224]],\n \n        [[252, 218, 182],\n         [252, 218, 182],\n         [252, 218, 182],\n         ...,\n         [252, 255, 223],\n         [250, 254, 225],\n         [248, 253, 224]],\n \n        ...,\n \n        [[127, 114,  92],\n         [135, 122, 100],\n         [159, 145, 126],\n         ...,\n         [203, 191, 179],\n         [199, 190, 180],\n         [196, 187, 177]],\n \n        [[142, 134, 117],\n         [151, 144, 127],\n         [168, 159, 145],\n         ...,\n         [198, 190, 183],\n         [194, 186, 179],\n         [192, 184, 177]],\n \n        [[139, 136, 131],\n         [152, 152, 146],\n         [167, 164, 160],\n         ...,\n         [189, 187, 186],\n         [192, 188, 187],\n         [193, 190, 186]]], dtype=uint8)\n orig_shape: (1837, 1378)\n path: '/kaggle/input/test-model/FullSizeRender.jpg'\n probs: None\n save_dir: 'runs/detect/predict'\n speed: {'preprocess': 2.52532958984375, 'inference': 7.536411285400391, 'postprocess': 1.3298988342285156},\n ultralytics.engine.results.Results object with attributes:\n \n boxes: ultralytics.engine.results.Boxes object\n keypoints: None\n masks: None\n names: {0: 'BMTA-bus', 1: 'Bus Line Number', 2: 'Bus Side Number', 3: 'Destination Sign', 4: 'TSB-Bus'}\n obb: None\n orig_img: array([[[20, 25, 28],\n         [20, 25, 28],\n         [20, 25, 28],\n         ...,\n         [18, 32, 28],\n         [47, 62, 58],\n         [60, 75, 71]],\n \n        [[20, 25, 28],\n         [20, 25, 28],\n         [19, 24, 27],\n         ...,\n         [ 8, 22, 18],\n         [35, 49, 45],\n         [46, 61, 57]],\n \n        [[19, 24, 27],\n         [19, 24, 27],\n         [18, 23, 26],\n         ...,\n         [ 0,  9,  7],\n         [18, 29, 26],\n         [26, 40, 36]],\n \n        ...,\n \n        [[19, 38, 51],\n         [22, 41, 54],\n         [26, 42, 58],\n         ...,\n         [17, 22, 21],\n         [17, 22, 21],\n         [17, 22, 21]],\n \n        [[28, 45, 58],\n         [29, 46, 59],\n         [31, 47, 60],\n         ...,\n         [18, 23, 22],\n         [17, 22, 21],\n         [17, 22, 21]],\n \n        [[32, 49, 62],\n         [32, 49, 62],\n         [32, 48, 61],\n         ...,\n         [19, 24, 23],\n         [18, 23, 22],\n         [16, 21, 20]]], dtype=uint8)\n orig_shape: (3024, 4032)\n path: '/kaggle/input/test-model/IMG_0050.JPG'\n probs: None\n save_dir: 'runs/detect/predict'\n speed: {'preprocess': 2.9981136322021484, 'inference': 7.644176483154297, 'postprocess': 1.5528202056884766},\n ultralytics.engine.results.Results object with attributes:\n \n boxes: ultralytics.engine.results.Boxes object\n keypoints: None\n masks: None\n names: {0: 'BMTA-bus', 1: 'Bus Line Number', 2: 'Bus Side Number', 3: 'Destination Sign', 4: 'TSB-Bus'}\n obb: None\n orig_img: array([[[140, 149, 153],\n         [140, 149, 153],\n         [142, 151, 155],\n         ...,\n         [202, 199, 161],\n         [203, 201, 161],\n         [203, 201, 161]],\n \n        [[142, 151, 155],\n         [142, 151, 155],\n         [144, 153, 157],\n         ...,\n         [202, 199, 161],\n         [204, 198, 161],\n         [202, 200, 160]],\n \n        [[145, 154, 158],\n         [146, 155, 159],\n         [148, 157, 161],\n         ...,\n         [203, 197, 160],\n         [204, 196, 159],\n         [202, 196, 159]],\n \n        ...,\n \n        [[173, 182, 179],\n         [171, 180, 177],\n         [168, 177, 174],\n         ...,\n         [185, 189, 194],\n         [185, 189, 194],\n         [185, 189, 194]],\n \n        [[177, 186, 183],\n         [175, 184, 181],\n         [173, 180, 177],\n         ...,\n         [179, 183, 188],\n         [178, 182, 187],\n         [178, 182, 187]],\n \n        [[177, 186, 183],\n         [175, 184, 181],\n         [174, 181, 178],\n         ...,\n         [178, 182, 187],\n         [176, 180, 185],\n         [176, 180, 185]]], dtype=uint8)\n orig_shape: (3024, 4032)\n path: '/kaggle/input/test-model/IMG_0051.JPG'\n probs: None\n save_dir: 'runs/detect/predict'\n speed: {'preprocess': 3.0083656311035156, 'inference': 7.0056915283203125, 'postprocess': 1.4345645904541016},\n ultralytics.engine.results.Results object with attributes:\n \n boxes: ultralytics.engine.results.Boxes object\n keypoints: None\n masks: None\n names: {0: 'BMTA-bus', 1: 'Bus Line Number', 2: 'Bus Side Number', 3: 'Destination Sign', 4: 'TSB-Bus'}\n obb: None\n orig_img: array([[[180, 201, 186],\n         [215, 236, 221],\n         [142, 160, 147],\n         ...,\n         [152, 152, 146],\n         [152, 152, 146],\n         [151, 151, 145]],\n \n        [[206, 227, 212],\n         [139, 160, 145],\n         [ 83, 101,  88],\n         ...,\n         [154, 154, 148],\n         [158, 158, 152],\n         [156, 156, 150]],\n \n        [[163, 181, 168],\n         [ 83, 101,  88],\n         [ 67,  85,  72],\n         ...,\n         [157, 154, 149],\n         [159, 159, 153],\n         [151, 151, 145]],\n \n        ...,\n \n        [[196, 196, 196],\n         [183, 183, 183],\n         [176, 176, 176],\n         ...,\n         [194, 190, 189],\n         [193, 189, 188],\n         [197, 195, 194]],\n \n        [[186, 186, 186],\n         [180, 180, 180],\n         [179, 179, 179],\n         ...,\n         [192, 188, 187],\n         [188, 184, 183],\n         [175, 171, 170]],\n \n        [[189, 189, 189],\n         [179, 179, 179],\n         [172, 172, 172],\n         ...,\n         [195, 190, 189],\n         [192, 188, 187],\n         [175, 171, 170]]], dtype=uint8)\n orig_shape: (3024, 4032)\n path: '/kaggle/input/test-model/IMG_0391.JPG'\n probs: None\n save_dir: 'runs/detect/predict'\n speed: {'preprocess': 3.123760223388672, 'inference': 7.575511932373047, 'postprocess': 1.4014244079589844},\n ultralytics.engine.results.Results object with attributes:\n \n boxes: ultralytics.engine.results.Boxes object\n keypoints: None\n masks: None\n names: {0: 'BMTA-bus', 1: 'Bus Line Number', 2: 'Bus Side Number', 3: 'Destination Sign', 4: 'TSB-Bus'}\n obb: None\n orig_img: array([[[253, 253, 253],\n         [253, 253, 253],\n         [253, 253, 253],\n         ...,\n         [ 62,  41,  26],\n         [ 64,  43,  28],\n         [ 55,  34,  19]],\n \n        [[253, 253, 253],\n         [253, 253, 253],\n         [253, 253, 253],\n         ...,\n         [ 60,  39,  24],\n         [ 65,  44,  29],\n         [ 64,  43,  28]],\n \n        [[253, 253, 253],\n         [253, 253, 253],\n         [253, 253, 253],\n         ...,\n         [ 55,  34,  19],\n         [ 56,  35,  20],\n         [ 58,  37,  22]],\n \n        ...,\n \n        [[143, 124, 109],\n         [150, 131, 116],\n         [157, 139, 122],\n         ...,\n         [155, 149, 138],\n         [156, 150, 139],\n         [148, 142, 131]],\n \n        [[153, 134, 119],\n         [156, 137, 122],\n         [166, 147, 132],\n         ...,\n         [149, 143, 132],\n         [155, 149, 138],\n         [147, 141, 130]],\n \n        [[154, 135, 120],\n         [163, 144, 129],\n         [169, 150, 135],\n         ...,\n         [151, 145, 134],\n         [153, 147, 136],\n         [148, 142, 131]]], dtype=uint8)\n orig_shape: (4032, 3024)\n path: '/kaggle/input/test-model/IMG_0421.JPG'\n probs: None\n save_dir: 'runs/detect/predict'\n speed: {'preprocess': 3.0486583709716797, 'inference': 7.621049880981445, 'postprocess': 1.3768672943115234},\n ultralytics.engine.results.Results object with attributes:\n \n boxes: ultralytics.engine.results.Boxes object\n keypoints: None\n masks: None\n names: {0: 'BMTA-bus', 1: 'Bus Line Number', 2: 'Bus Side Number', 3: 'Destination Sign', 4: 'TSB-Bus'}\n obb: None\n orig_img: array([[[246, 215, 182],\n         [246, 215, 182],\n         [246, 215, 182],\n         ...,\n         [ 26,  17,  14],\n         [ 24,  15,  12],\n         [ 21,  12,   9]],\n \n        [[245, 214, 181],\n         [246, 215, 182],\n         [246, 215, 182],\n         ...,\n         [ 19,  10,   7],\n         [ 26,  17,  14],\n         [ 37,  28,  25]],\n \n        [[248, 217, 184],\n         [247, 216, 183],\n         [247, 216, 183],\n         ...,\n         [ 23,  14,  11],\n         [ 34,  25,  22],\n         [ 33,  24,  21]],\n \n        ...,\n \n        [[129, 120, 107],\n         [140, 131, 118],\n         [145, 136, 123],\n         ...,\n         [108, 109, 107],\n         [ 80,  81,  79],\n         [ 45,  43,  42]],\n \n        [[139, 130, 117],\n         [141, 132, 119],\n         [157, 148, 135],\n         ...,\n         [124, 124, 124],\n         [ 66,  66,  66],\n         [ 52,  52,  52]],\n \n        [[145, 136, 123],\n         [160, 151, 138],\n         [149, 140, 127],\n         ...,\n         [130, 132, 132],\n         [ 57,  57,  57],\n         [ 70,  70,  70]]], dtype=uint8)\n orig_shape: (4032, 3024)\n path: '/kaggle/input/test-model/IMG_0422.JPG'\n probs: None\n save_dir: 'runs/detect/predict'\n speed: {'preprocess': 2.8963088989257812, 'inference': 6.938457489013672, 'postprocess': 1.4116764068603516},\n ultralytics.engine.results.Results object with attributes:\n \n boxes: ultralytics.engine.results.Boxes object\n keypoints: None\n masks: None\n names: {0: 'BMTA-bus', 1: 'Bus Line Number', 2: 'Bus Side Number', 3: 'Destination Sign', 4: 'TSB-Bus'}\n obb: None\n orig_img: array([[[157, 158, 156],\n         [153, 154, 152],\n         [153, 154, 152],\n         ...,\n         [119, 116, 112],\n         [114, 111, 107],\n         [108, 105, 101]],\n \n        [[158, 159, 157],\n         [156, 157, 155],\n         [159, 160, 158],\n         ...,\n         [121, 118, 114],\n         [114, 111, 107],\n         [105, 102,  98]],\n \n        [[158, 159, 157],\n         [156, 157, 155],\n         [161, 162, 160],\n         ...,\n         [111, 108, 104],\n         [119, 116, 112],\n         [105, 102,  98]],\n \n        ...,\n \n        [[ 74,  85, 113],\n         [ 73,  84, 112],\n         [ 73,  84, 112],\n         ...,\n         [ 14,  13,  29],\n         [ 20,  19,  35],\n         [ 19,  18,  34]],\n \n        [[ 73,  84, 112],\n         [ 72,  83, 111],\n         [ 72,  83, 110],\n         ...,\n         [ 27,  24,  39],\n         [ 31,  28,  43],\n         [ 23,  20,  35]],\n \n        [[ 71,  82, 110],\n         [ 71,  82, 110],\n         [ 70,  81, 108],\n         ...,\n         [ 49,  46,  61],\n         [ 41,  38,  53],\n         [ 28,  25,  40]]], dtype=uint8)\n orig_shape: (4032, 3024)\n path: '/kaggle/input/test-model/IMG_0564.JPG'\n probs: None\n save_dir: 'runs/detect/predict'\n speed: {'preprocess': 2.9702186584472656, 'inference': 7.087469100952148, 'postprocess': 1.390695571899414},\n ultralytics.engine.results.Results object with attributes:\n \n boxes: ultralytics.engine.results.Boxes object\n keypoints: None\n masks: None\n names: {0: 'BMTA-bus', 1: 'Bus Line Number', 2: 'Bus Side Number', 3: 'Destination Sign', 4: 'TSB-Bus'}\n obb: None\n orig_img: array([[[172, 158, 139],\n         [173, 159, 140],\n         [169, 154, 135],\n         ...,\n         [254, 244, 227],\n         [230, 220, 203],\n         [194, 184, 167]],\n \n        [[189, 175, 156],\n         [177, 163, 144],\n         [183, 168, 149],\n         ...,\n         [238, 228, 211],\n         [212, 202, 185],\n         [205, 195, 178]],\n \n        [[179, 165, 146],\n         [175, 161, 142],\n         [177, 162, 143],\n         ...,\n         [231, 221, 204],\n         [194, 184, 167],\n         [200, 190, 173]],\n \n        ...,\n \n        [[123, 131, 130],\n         [134, 142, 141],\n         [154, 162, 161],\n         ...,\n         [175, 177, 177],\n         [186, 188, 188],\n         [166, 168, 168]],\n \n        [[180, 191, 189],\n         [166, 177, 175],\n         [153, 164, 162],\n         ...,\n         [185, 190, 189],\n         [162, 164, 164],\n         [176, 178, 178]],\n \n        [[241, 252, 250],\n         [196, 207, 205],\n         [183, 194, 192],\n         ...,\n         [182, 187, 186],\n         [170, 172, 172],\n         [165, 167, 167]]], dtype=uint8)\n orig_shape: (3024, 4032)\n path: '/kaggle/input/test-model/IMG_0575.JPG'\n probs: None\n save_dir: 'runs/detect/predict'\n speed: {'preprocess': 3.1135082244873047, 'inference': 8.056163787841797, 'postprocess': 1.4333724975585938},\n ultralytics.engine.results.Results object with attributes:\n \n boxes: ultralytics.engine.results.Boxes object\n keypoints: None\n masks: None\n names: {0: 'BMTA-bus', 1: 'Bus Line Number', 2: 'Bus Side Number', 3: 'Destination Sign', 4: 'TSB-Bus'}\n obb: None\n orig_img: array([[[173, 167, 156],\n         [179, 173, 162],\n         [226, 222, 211],\n         ...,\n         [180, 185, 184],\n         [185, 190, 188],\n         [176, 181, 179]],\n \n        [[188, 182, 171],\n         [174, 168, 157],\n         [228, 224, 213],\n         ...,\n         [169, 174, 173],\n         [165, 170, 168],\n         [170, 175, 173]],\n \n        [[175, 169, 158],\n         [178, 172, 161],\n         [228, 224, 213],\n         ...,\n         [156, 162, 161],\n         [159, 165, 164],\n         [160, 166, 165]],\n \n        ...,\n \n        [[171, 176, 179],\n         [160, 165, 168],\n         [150, 155, 156],\n         ...,\n         [174, 178, 179],\n         [173, 177, 178],\n         [170, 174, 175]],\n \n        [[177, 178, 182],\n         [179, 180, 184],\n         [150, 152, 153],\n         ...,\n         [169, 173, 174],\n         [172, 176, 177],\n         [165, 169, 170]],\n \n        [[149, 150, 154],\n         [153, 154, 158],\n         [140, 142, 143],\n         ...,\n         [176, 180, 181],\n         [170, 174, 175],\n         [164, 168, 169]]], dtype=uint8)\n orig_shape: (4032, 3024)\n path: '/kaggle/input/test-model/IMG_0664.JPG'\n probs: None\n save_dir: 'runs/detect/predict'\n speed: {'preprocess': 2.9397010803222656, 'inference': 7.886648178100586, 'postprocess': 1.4920234680175781},\n ultralytics.engine.results.Results object with attributes:\n \n boxes: ultralytics.engine.results.Boxes object\n keypoints: None\n masks: None\n names: {0: 'BMTA-bus', 1: 'Bus Line Number', 2: 'Bus Side Number', 3: 'Destination Sign', 4: 'TSB-Bus'}\n obb: None\n orig_img: array([[[ 59,  55,  54],\n         [ 62,  58,  57],\n         [ 58,  54,  53],\n         ...,\n         [245, 238, 223],\n         [245, 238, 223],\n         [245, 238, 223]],\n \n        [[ 52,  48,  47],\n         [ 56,  52,  51],\n         [ 53,  49,  48],\n         ...,\n         [245, 238, 223],\n         [245, 238, 223],\n         [245, 238, 223]],\n \n        [[ 53,  49,  48],\n         [ 62,  58,  57],\n         [ 62,  58,  57],\n         ...,\n         [244, 237, 222],\n         [244, 237, 222],\n         [244, 237, 222]],\n \n        ...,\n \n        [[117, 154, 174],\n         [121, 158, 178],\n         [104, 141, 161],\n         ...,\n         [ 25,  48,  80],\n         [ 25,  48,  80],\n         [ 24,  47,  79]],\n \n        [[149, 184, 204],\n         [124, 159, 179],\n         [123, 158, 178],\n         ...,\n         [ 25,  48,  80],\n         [ 25,  48,  80],\n         [ 25,  48,  80]],\n \n        [[153, 188, 208],\n         [136, 171, 191],\n         [111, 146, 166],\n         ...,\n         [ 26,  49,  81],\n         [ 26,  49,  81],\n         [ 26,  49,  81]]], dtype=uint8)\n orig_shape: (4032, 3024)\n path: '/kaggle/input/test-model/IMG_1976.jpeg'\n probs: None\n save_dir: 'runs/detect/predict'\n speed: {'preprocess': 2.9726028442382812, 'inference': 6.853342056274414, 'postprocess': 1.3806819915771484}]"},"metadata":{}}]}]}